{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasetの実装\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセットのダウンロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import tarfile\n",
    "import os.path as osp\n",
    "from os.path import expanduser\n",
    "home = expanduser(\"~\")\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(home, \"data/\")        \n",
    "if not os.path.exists(data_dir):\n",
    "    os.mkdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights_dir = \"./weights\"\n",
    "if not os.path.exists(weights_dir):\n",
    "    os.mkdir(weights_dir)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://host.robots.ox.ac.uk/pascal/VOC/voc2012/VOCtrainval_11-May-2012.tar\"\n",
    "target_path = os.path.join(data_dir, \"VOCtrainval_11-May-2012.tar\")\n",
    "#print(os.path.exists(target_path))\n",
    "\n",
    "if not os.path.exists(target_path):\n",
    "    urllib.request.urlretrieve(url, target_path)\n",
    "    \n",
    "    tar = tarfile.TarFile(target_path)  #tarfile読み込み\n",
    "    tar.extractall(data_dir)            #tarを解凍\n",
    "    tar.close                           #tarをクローズ\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データセット作成"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "・訓練時のDataAugumentationの際に、アノテーションデータも変換する必要があるのに注意"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像とアノテーションデータへのファイルパスリストを作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_datapath_list(rootpath):\n",
    "    \n",
    "    \n",
    "    imgpath_template = osp.join(rootpath, \"JPEGImages\", \"%s.jpg\")\n",
    "    annopath_template = osp.join(rootpath, \"Annotations\", \"%s.xml\")\n",
    "    \n",
    "    train_id_names = osp.join(rootpath, \"ImageSets/Main/train.txt\")\n",
    "    val_id_names = osp.join(rootpath, \"ImageSets/Main/val.txt\")\n",
    "    \n",
    "    train_img_list=list()\n",
    "    train_anno_list = list()\n",
    "    \n",
    "    for line in open(train_id_names):\n",
    "        file_id = line.strip()  #空白スペースと改行を除去\n",
    "        img_path=(imgpath_template % file_id)                   #「%s」の部分にfile_idを代入\n",
    "        anno_path=(annopath_template % file_id)\n",
    "        train_img_list.append(img_path)\n",
    "        train_anno_list.append(anno_path)\n",
    "        \n",
    "    val_img_list = list()\n",
    "    val_anno_list = list()\n",
    "    \n",
    "    for line in open(val_id_names):\n",
    "        file_id = line.strip()\n",
    "        img_path = (imgpath_template % file_id)\n",
    "        anno_path = (annopath_template % file_id)\n",
    "        val_img_list.append(img_path)\n",
    "        val_anno_list.append(anno_path)\n",
    "        \n",
    "    return train_img_list, train_anno_list, val_img_list, val_anno_list\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/yoshiki/data//VOCdevkit/VOC2012/JPEGImages/2008_000008.jpg\n"
     ]
    }
   ],
   "source": [
    "rootpath = osp.join(data_dir + \"/VOCdevkit/VOC2012\")\n",
    "train_img_list, train_anno_list, val_img_list, val_anno_list = make_datapath_list(rootpath)\n",
    "\n",
    "#動作確認\n",
    "print(train_img_list[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xml形式のアノテーションデータをリストに変換  \n",
    "・クラス名を文字列から数値へと置き換える  \n",
    "・アノテーションデータ（バウンディングボックスの座標）を画像サイズで規格化する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XMLをファイルやテキストから読み込んだり、加工したり、保存したりするためのライブラリ\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#XML形式のアノテーションを，リスト形式に変換する\n",
    "class Anno_xml2list(object):\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "        \n",
    "    def __call__(self, xml_path, width, height):\n",
    "        \n",
    "        ret = []                #[[xmin, ymin, xmax, ymax, label_index], ・・・]\n",
    "        \n",
    "        xml = ET.parse(xml_path).getroot()   #xmlファイルを読み込む\n",
    "        \n",
    "        for obj in xml.iter(\"object\"):      #画像内のobjectの数だけループする\n",
    "            \n",
    "            #アノテーションで検知がdifficultに設定されているものは除外\n",
    "            difficult = int(obj.find(\"difficult\").text)\n",
    "            if difficult:\n",
    "                continue\n",
    "            \n",
    "            bndbox = []                                   #1つの物体に対するアノテーションを格納するリスト\n",
    "            \n",
    "            name = obj.find(\"name\").text.lower().strip()  #物体名(str.lower():すべての文字を小文字に変換. / str.strip():両端の指定の文字を削除)\n",
    "            bbox = obj.find(\"bndbox\")                     #バウンディングボックスの情報\n",
    "            \n",
    "            pts = [\"xmin\", \"ymin\", \"xmax\", \"ymax\"]\n",
    "            \n",
    "            for pt in (pts):\n",
    "                cur_pixel = int(bbox.find(pt).text)-1    #vocデータは原点が(1,1)なので、1を引いて(0,0)にする\n",
    "                \n",
    "                if pt == \"xmin\" or pt == \"xmax\":\n",
    "                    cur_pixel /= width                  #x方向は幅で割る\n",
    "                else:\n",
    "                    cur_pixel /= height\n",
    "\n",
    "                bndbox.append(cur_pixel)\n",
    "\n",
    "            label_idx = self.classes.index(name)\n",
    "            bndbox.append(label_idx)\n",
    "\n",
    "            ret += [bndbox]\n",
    "            \n",
    "        return np.array(ret)\n",
    "            \n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09        0.03003003  0.998       0.996997   18.        ]\n",
      " [ 0.122       0.56756757  0.164       0.72672673 14.        ]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nXML=ET.parse(xml_path).getroot()\\nfor child in XML:\\n    print(child.tag, child.attrib)\\n'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "voc_classes=[\"aeroplane\", \"bicycle\", \"bird\", \"boat\", \"bottle\", \"bus\", \"car\", \"cat\", \"chair\", \"cow\", \"diningtable\", \n",
    "             \"dog\", \"horse\", \"motorbike\", \"person\", \"pottedplant\", \"sheep\", \"sofa\", \"train\", \"tvmonitor\"]\n",
    "\n",
    "transform_anno=Anno_xml2list(voc_classes)\n",
    "\n",
    "test_img=cv2.imread(val_img_list[1])\n",
    "print(transform_anno(val_anno_list[1], test_img.shape[1], test_img.shape[0]))\n",
    "\n",
    "\n",
    "#img=cv2.imread(\"path\")   img.shape=height, width, channels\n",
    "\n",
    "#xmlファイルの中身の確認\n",
    "\"\"\"\n",
    "XML=ET.parse(xml_path).getroot()\n",
    "for child in XML:\n",
    "    print(child.tag, child.attrib)\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 画像とアノテーションの前処理を行うクラスDataTransformを作成\n",
    "訓練時はデータオーグメンテーション\n",
    "- 色調を変換し，画像の大きさを変更してからランダムに切り出す．さらに画像の大きさをリサイズし，色情報の平均値を引き算\n",
    "\n",
    "\n",
    "推論時は画像の大きさを変換し，色情報の平均値を引き算するだけ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_augumentation import Compose, ConvertFromInts, ToAbsoluteCoords, PhotometricDistort, Expand, RandomSampleCrop, RandomMirror, ToPercentCoords, Resize, SubtractMeans\n",
    "\n",
    "class DataTransform():\n",
    "    def __init__(self, input_size, color_mean):\n",
    "        self.data_transform = {\n",
    "            \n",
    "        }\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
